{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from numpy.linalg import inv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from numpy import expand_dims\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_array(name):\n",
    "    img = load_img(name)\n",
    "    img_array = img_to_array(img)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_img(img_name):\n",
    "  img = image_array(img_name)\n",
    "  h = 8\n",
    "  w = 8\n",
    "  feature = []\n",
    "  for a in range(0, (img.shape[0]-h)+1, h):\n",
    "    for b in range(0, (img.shape[1]-w)+1, w):\n",
    "      block = img[a:a+h, b:b+w]\n",
    "      my_block = (block.flatten())\n",
    "      feature.append(my_block)\n",
    "  return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1, cat2, dog1, dog2 = block_img('cat1.jpg'), block_img('cat2.jpg'),\\\n",
    "      block_img('dog1.jpg'), block_img('dog2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2, df3, df4 = pd.DataFrame(cat1), pd.DataFrame(cat2),\\\n",
    "pd.DataFrame(dog1), pd.DataFrame(dog2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['label'], df2['label'] =0,0\n",
    "df3['label'], df4['label'] = 1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4], axis =0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting 2D for ds\n",
    "x = df[7]\n",
    "y = df[35]\n",
    "label = df[\"label\"]\n",
    "color = ['orange', 'black']\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.scatter(x, y, c=label, cmap=matplotlib.colors.ListedColormap(color))\n",
    "plt.title(\"2D\")\n",
    "plt.xlabel(\"7th feature\")\n",
    "plt.ylabel(\"35th feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checker(df):\n",
    "    if df.isnull().sum().sum()==0:\n",
    "        print(\"Full data\")\n",
    "    if df.shape[1]<df.shape[0]:\n",
    "        print(\"Low dimensional\")\n",
    "    a = df.describe()\n",
    "    if np.max(a[a.index=='mean'].values)-np.min(a[a.index=='mean'].values)>100:\n",
    "        print(\"Scale problem\")\n",
    "checker(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = [df[7]]\n",
    "f7 = [df[9]]\n",
    "plt.hist(f3, alpha=0.5, label='f3', bins=30)\n",
    "plt.hist(f7, alpha=0.5, label='f7', bins=30)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Data\n",
    "f3 = df[7]\n",
    "f7 = df[9]\n",
    "\n",
    "# Create histogram traces\n",
    "trace_f3 = go.Histogram(\n",
    "    x=f3,\n",
    "    name='f3',\n",
    "    opacity=0.5,\n",
    "    nbinsx=30\n",
    ")\n",
    "trace_f7 = go.Histogram(\n",
    "    x=f7,\n",
    "    name='f7',\n",
    "    opacity=0.5,\n",
    "    nbinsx=30\n",
    ")\n",
    "\n",
    "# Create layout\n",
    "layout = go.Layout(\n",
    "    title='Histogram of f3 and f7',\n",
    "    xaxis=dict(title='Values'),\n",
    "    yaxis=dict(title='Frequency'),\n",
    "    barmode='overlay'\n",
    ")\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure(data=[trace_f3, trace_f7], layout=layout)\n",
    "\n",
    "# Display the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column = [7,8,9,10,11,12])\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Select the desired columns\n",
    "columns = [7, 8, 9, 10, 11, 12]\n",
    "\n",
    "# Create box plot traces\n",
    "traces = []\n",
    "for column in columns:\n",
    "    trace = go.Box(\n",
    "        y=df[column],\n",
    "        name=f'Column {column}',\n",
    "        boxpoints='all',\n",
    "        jitter=0.5,\n",
    "        whiskerwidth=0.2,\n",
    "        marker=dict(size=2),\n",
    "        line=dict(width=1)\n",
    "    )\n",
    "    traces.append(trace)\n",
    "\n",
    "# Create layout\n",
    "layout = go.Layout(\n",
    "    title='Box Plot',\n",
    "    yaxis=dict(title='Values')\n",
    ")\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "\n",
    "# Display the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(df):\n",
    "    X = df.iloc[:, 0:192].values\n",
    "    y = df.iloc[:, 192].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=0, shuffle = True)\n",
    "        \n",
    "    my_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    X_train_std = my_scaler.fit_transform(X_train)\n",
    "    X_test_std = my_scaler.fit_transform(X_test)\n",
    "    return X_train_std, X_test_std,  y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std, X_test_std,  y_train, y_test = scaling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_lda(df):\n",
    "    X_train_std, X_test_std,  y_train, y_test = scaling(df)\n",
    "    lr_normal = LogisticRegression()\n",
    "    lr_normal = lr_normal.fit(X_train_std, y_train)\n",
    "    pred_normal=lr_normal.predict(X_test_std)\n",
    "    print (\"Classification Report\")\n",
    "    print(classification_report(y_test, pred_normal))\n",
    "    print (\"Confusion Report\")\n",
    "    print(confusion_matrix(y_test, pred_normal))\n",
    "    return lr_normal, pred_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_normal, pred_normal = lr_lda(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(X_train_std[3], kde = True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covMatrix_train = np.cov(y_train,bias=True)\n",
    "covMatrix_test = np.cov(X_test_std, bias = True)\n",
    "print(covMatrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std, X_test_std,  y_train, y_test = scaling(df)\n",
    "X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA(df):\n",
    "    X_train_std, X_test_std,  y_train, y_test = scaling(df)\n",
    "    n_components = min(X_train_std.shape[1], len(np.unique(y_train))) - 1\n",
    "    lda = LinearDiscriminantAnalysis(n_components=n_components)\n",
    "    X_train_LDA = lda.fit_transform(X_train_std, y_train)\n",
    "    X_test_LDA = lda.fit_transform(X_test_std, y_test)\n",
    "\n",
    "    lr_lda = LogisticRegression()\n",
    "    lr_lda = lr_lda.fit(X_train_LDA, y_train)\n",
    "\n",
    "    pred_lda=lr_lda.predict(X_test_LDA)\n",
    "    print (\"Classification Report\")\n",
    "    print(classification_report(y_test, pred_lda))\n",
    "    print (\"Confusion Report\")\n",
    "    print(confusion_matrix(y_test, pred_lda))\n",
    "    return pred_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lda = LDA(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression_PCA(df):\n",
    "    X_train_std, X_test_std,  y_train, y_test = scaling(df)\n",
    "\n",
    "    pca = PCA(n_components= 2) \n",
    "    X_train_PCA = pca.fit_transform(X_train_std)\n",
    "    X_test_PCA = pca.transform(X_test_std)\n",
    "\n",
    "    log_r1 = LogisticRegression()\n",
    "    log_r1.fit(X_train_PCA, y_train)\n",
    "\n",
    "    pred1=log_r1.predict(X_test_PCA)\n",
    "\n",
    "    print (\"Classification Report\")\n",
    "    print(classification_report(y_test, pred1))\n",
    "\n",
    "    print (\"Confusion Report\")\n",
    "    print(confusion_matrix(y_test, pred1))\n",
    "\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    return pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = LogisticRegression_PCA(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_LDA_Random(df):\n",
    "    X_train_std, X_test_std,  y_train, y_test = scaling(df)\n",
    "\n",
    "    pipeline = Pipeline([('pca', PCA(n_components= 2)), ('clf',  RandomForestRegressor(n_estimators=20,random_state=42))])\n",
    "    pipeline.fit(X_train_std, y_train)\n",
    "    print('Test Accuracy: %.3f' %pipeline.score(X_test_std, y_test))\n",
    "\n",
    "    n_components = min(X_train_std.shape[1], len(np.unique(y_train))) - 1\n",
    "    \n",
    "    pipeline2 = Pipeline([('pca', LinearDiscriminantAnalysis(n_components= n_components)), \\\n",
    "                         ('clf', RandomForestRegressor(n_estimators = 20, random_state=42))])\n",
    "\n",
    "    pipeline2.fit(X_train_std, y_train)\n",
    "    print('Test Accuracy: %.3f' %pipeline2.score(X_test_std, y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_LDA_Random(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def Sequential_Model(df):\n",
    "    X_train_std, X_test_std, y_train, y_test = scaling(df)\n",
    "\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units=800, kernel_initializer='uniform', activation='relu', input_shape=(192,)))\n",
    "    classifier.add(Dense(units=600, kernel_initializer='uniform', activation='relu'))\n",
    "    classifier.add(Dense(units=400, kernel_initializer='uniform', activation='relu'))\n",
    "    classifier.add(Dense(units=2, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD()\n",
    "    classifier.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])\n",
    "    classifier.fit(X_train_std, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "    predictions = classifier.predict(X_test_std)\n",
    "    prediction = tf.argmax(predictions, axis=1)\n",
    "\n",
    "    CC_test = tf.math.confusion_matrix(y_test, prediction)\n",
    "    TN = CC_test[1, 1]\n",
    "    FP = CC_test[1, 0]\n",
    "    FN = CC_test[0, 1]\n",
    "    TP = CC_test[0, 0]\n",
    "    FPFN = FP + FN\n",
    "    TPTN = TP + TN\n",
    "    Accuracy = 1 / (1 + (FPFN / TPTN))\n",
    "    print(\"Our_Accuracy_Score:\", Accuracy)\n",
    "    Precision = 1 / (1 + (FP / TP))\n",
    "    print(\"Our_Precision_Score:\", Precision)\n",
    "    Sensitivity = 1 / (1 + (FN / TP))\n",
    "    print(\"Our_Sensitivity_Score:\", Sensitivity)\n",
    "    Specificity = 1 / (1 + (FP / TN))\n",
    "    print(\"Our_Specificity_Score:\", Specificity)\n",
    "\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequential_Model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
